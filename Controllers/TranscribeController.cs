using Microsoft.AspNetCore.Mvc;
using OpenAI.Audio;
using YoutubeExplode;
using YoutubeExplode.Videos.ClosedCaptions;
using YoutubeExplode.Videos.Streams;

namespace YtTranscribeApi.Controllers;

[ApiController]
[Route("api")]
public class TranscribeController : ControllerBase
{
    private readonly IConfiguration _cfg;
    private readonly ILogger<TranscribeController> _log;

    public TranscribeController(IConfiguration cfg, ILogger<TranscribeController> log)
    {
        _cfg = cfg;
        _log = log;
    }

    public record TranscribeReq(string url, string? preferLanguage, bool forceOpenAi = false);
    public record TranscribeRes(bool ok, string source, string transcript, string? note = null);

    [HttpPost("transcribe")]
    public async Task<IActionResult> Transcribe([FromBody] TranscribeReq req, CancellationToken ct)
    {
        _log.LogInformation("START transcribe url={Url}", req.url);

        if (string.IsNullOrWhiteSpace(req.url))
            return BadRequest(new { ok = false, error = "url required" });

        var yt = new YoutubeClient();

        // 1) Caption dene
        if (!req.forceOpenAi)
        {
            try
            {
                _log.LogInformation("Trying captions... preferLanguage={Lang}", req.preferLanguage);

                var captionText = await TryGetCaptionAsync(yt, req.url, req.preferLanguage, ct);
                if (!string.IsNullOrWhiteSpace(captionText))
                {
                    _log.LogInformation("Captions FOUND length={Len}", captionText.Length);
                    return Ok(new TranscribeRes(true, "captions", captionText));
                }

                _log.LogInformation("Captions NOT found");
            }
            catch (Exception ex)
            {
                _log.LogWarning(ex, "Caption flow failed, will fallback to OpenAI.");
            }
        }
        else
        {
            _log.LogInformation("forceOpenAi=true -> skipping captions");
        }

        // 2) OpenAI Transcribe
        var apiKey = _cfg["OPENAI_API_KEY"] ?? Environment.GetEnvironmentVariable("OPENAI_API_KEY");
        if (string.IsNullOrWhiteSpace(apiKey))
            return StatusCode(500, new { ok = false, error = "OPENAI_API_KEY env missing" });

        try
        {
            _log.LogInformation("Fallback to OpenAI transcription...");

            var transcript = await TranscribeWithOpenAiAsync(yt, req.url, apiKey, req.preferLanguage, ct);

            _log.LogInformation("DONE openai transcriptLen={Len}", transcript.Length);

            return Ok(new TranscribeRes(
                ok: true,
                source: "openai",
                transcript: transcript,
                note: "Caption yok/erişilemedi, OpenAI kullanıldı."
            ));
        }
        catch (Exception ex)
        {
            _log.LogError(ex, "OpenAI transcription failed");
            return StatusCode(500, new { ok = false, error = "Transcription failed", details = ex.Message });
        }
        finally
        {
            _log.LogInformation("END transcribe");
        }
    }

    private async Task<string?> TryGetCaptionAsync(
        YoutubeClient yt,
        string url,
        string? preferLanguage,
        CancellationToken ct)
    {
        var manifest = await yt.Videos.ClosedCaptions.GetManifestAsync(url, ct);
        _log.LogInformation("Caption tracks count={Count}", manifest.Tracks.Count);

        if (!manifest.Tracks.Any())
            return null;

        ClosedCaptionTrackInfo? trackInfo = null;

        if (!string.IsNullOrWhiteSpace(preferLanguage))
        {
            trackInfo = manifest.Tracks
                .Where(t => string.Equals(t.Language.Code, preferLanguage, StringComparison.OrdinalIgnoreCase))
                .OrderByDescending(t => t.IsAutoGenerated ? 0 : 1) // manuel > auto
                .FirstOrDefault();

            if (trackInfo != null)
                _log.LogInformation("Selected caption track by lang={Lang} auto={Auto}",
                    trackInfo.Language.Code, trackInfo.IsAutoGenerated);
        }

        trackInfo ??= manifest.Tracks
            .OrderByDescending(t => t.IsAutoGenerated ? 0 : 1)
            .FirstOrDefault();

        if (trackInfo is null)
            return null;

        _log.LogInformation("Selected caption track lang={Lang} auto={Auto}",
            trackInfo.Language.Code, trackInfo.IsAutoGenerated);

        ClosedCaptionTrack track = await yt.Videos.ClosedCaptions.GetAsync(trackInfo, ct);

        var text = string.Join(" ",
            track.Captions
                 .Select(c => c.Text)
                 .Where(x => !string.IsNullOrWhiteSpace(x))
        );

        _log.LogInformation("Captions text length={Len}", text.Length);

        return string.IsNullOrWhiteSpace(text) ? null : text;
    }

    private async Task<string> TranscribeWithOpenAiAsync(
        YoutubeClient yt,
        string url,
        string apiKey,
        string? preferLanguage,
        CancellationToken ct)
    {
        _log.LogInformation("Fetching stream manifest...");
        var streamManifest = await yt.Videos.Streams.GetManifestAsync(url, ct);

        var audioStreamInfo = streamManifest
            .GetAudioOnlyStreams()
            .OrderByDescending(s => s.Bitrate)
            .FirstOrDefault();

        if (audioStreamInfo is null)
            throw new InvalidOperationException("No audio stream found.");

        _log.LogInformation("Selected audio: container={Container} bitrate={Bitrate} size={Size}",
            audioStreamInfo.Container.Name,
            audioStreamInfo.Bitrate,
            audioStreamInfo.Size);

        var tempPath = Path.Combine(
            Path.GetTempPath(),
            $"yt-audio-{Guid.NewGuid():N}.{audioStreamInfo.Container.Name}"
        );

        _log.LogInformation("Downloading audio to tempPath={TempPath}", tempPath);

        var sw = System.Diagnostics.Stopwatch.StartNew();

        await using (var fs = System.IO.File.OpenWrite(tempPath))
        {
            await yt.Videos.Streams.CopyToAsync(audioStreamInfo, fs, progress: null, cancellationToken: ct);
        }

        sw.Stop();

        long fileBytes = 0;
        try { fileBytes = new FileInfo(tempPath).Length; } catch { }

        _log.LogInformation("Audio downloaded in {Ms}ms, bytes={Bytes}", sw.ElapsedMilliseconds, fileBytes);

        try
        {
            _log.LogInformation("Calling OpenAI Transcribe... lang={Lang}", preferLanguage);

            var audio = new AudioClient("whisper-1", apiKey);

            await using var fileStream = System.IO.File.OpenRead(tempPath);

            var options = new AudioTranscriptionOptions
            {
                Language = string.IsNullOrWhiteSpace(preferLanguage) ? null : preferLanguage
            };

            var swAi = System.Diagnostics.Stopwatch.StartNew();

            var res = await audio.TranscribeAudioAsync(fileStream, Path.GetFileName(tempPath), options, ct);

            swAi.Stop();

            var text = res.Value.Text?.Trim();
            _log.LogInformation("OpenAI transcribe done in {Ms}ms, textLen={Len}",
                swAi.ElapsedMilliseconds, text?.Length ?? 0);

            if (string.IsNullOrWhiteSpace(text))
                throw new InvalidOperationException("OpenAI returned empty transcript.");

            return text!;
        }
        finally
        {
            try
            {
                System.IO.File.Delete(tempPath);
                _log.LogInformation("Temp file deleted");
            }
            catch (Exception ex)
            {
                _log.LogWarning(ex, "Temp file delete failed");
            }
        }
    }
}
